{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Initializes DLC project for ephys tracking. \n",
    "\n",
    "** Run locally to run dlc GUI for labelling images **\n",
    "\n",
    "To run: \n",
    "1. Run Anaconda prompt as Administrator \n",
    "2. Activate DLC enviornment \n",
    "    ``` conda activate DLC-GPU ```\n",
    "3. cd to project folder \n",
    "\n",
    "    ``` F: ``` * if not in F drive\n",
    "    \n",
    "    ``` cd F:\\ClarkP30_Recordings ```\n",
    "3. Open Jupyter Lab \n",
    "    ``` jupyter lab ```\n",
    "4. Open ephys_tracking.ipynb found in ```F:\\ClarkP30_Recordings\\DLC```\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import deeplabcut toolbox "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import deeplabcut "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup Project details"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Setup Project \r\n",
    "task = 'linear_track' # Enter the name of your experiment Task\r\n",
    "experimenter = 'Berkowitz' # Enter the name of the experimenter\r\n",
    "project_path = 'D:/DLC_analysis/app_ps1/' "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set paths to video files used for generating your training set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#These are the paths to the videos you'll be using to pull images for training set\r\n",
    "import glob as glob\r\n",
    "\r\n",
    "vid_path = 'D:/DLC_analysis/app_ps1/Videos//'\r\n",
    "video = glob.glob(vid_path+'*.avi') # Enter the paths of your videos OR FOLDER you want to grab frames from."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For .mpg files, run the following in the terminal to convert to .avi\r\n",
    "Several bugs exsist for .mpg files when running DLC. Easiest to just convert to default. \r\n",
    "\r\n",
    "Navigate to videos. \r\n",
    "\r\n",
    "``` cd D:/DLC_analysis/app_ps1/Videos// ```\r\n",
    "\r\n",
    "Use ffmpeg to convert from .mpg to .avi. \r\n",
    "\r\n",
    "``` ffmpeg -i video_name.mpg -crf 17 video_name.avi ```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize your project directory. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "path_config_file = deeplabcut.create_new_project(task,experimenter,video,copy_videos=True) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Project \"C:\\Users\\schafferlab\\Documents\\GitHub\\position_tracking\\linear_track-Berkowitz-2021-11-15\" already exists!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edit config file. \n",
    "\n",
    "* change bodyparts from default to red & green leds\n",
    "* change skeleton labels\n",
    "* set number of frames to use for training to 60\n",
    "* set network type at resnet_101 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Open config.yaml file, change parameters, save back to directory"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import ruamel.yaml\r\n",
    "\r\n",
    "config_path = 'd:\\\\Users\\\\BClarkLab\\\\GoogleDrive_\\\\DLC_analysis\\\\ephys_bitfields-Berkowitz-2021-02-09\\\\config.yaml'\r\n",
    "\r\n",
    "yaml = ruamel.yaml.YAML()\r\n",
    "# yaml.preserve_quotes = True\r\n",
    "with open(config_path) as fp:\r\n",
    "    data = yaml.load(fp)\r\n",
    "# Update config file to track leds     \r\n",
    "data['bodyparts'] = ['red_led','green_led']\r\n",
    "data['skeleton'] =[['red_led','green_led']]\r\n",
    "data['numframes2pick'] = 60\r\n",
    "data['default_net_type'] = 'resnet_101'\r\n",
    "\r\n",
    "with open(config_path, \"w\") as f:\r\n",
    "    yaml.dump(data, f)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract frames from videos for training\n",
    "\n",
    "```extract_frames``` will ask if you want to extract frames for each video. yes to include frames from that video or no to skip."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "deeplabcut.extract_frames(config_path,mode = 'automatic',algo = 'kmeans', crop = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Label Frames "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# config_path = 'F:\\\\ClarkP30_Recordings\\\\DLC\\\\ephys-Berkowitz-2020-09-18\\\\config.yaml'\n",
    "deeplabcut.label_frames(config_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### All set to train your network :) \n",
    "\n",
    "* Use Colab_TrainNetwork_VideoAnalysis.ipynb to create training dataset,train network, and analyze your videos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.12 64-bit ('DEEPLABCUT': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "interpreter": {
   "hash": "4163bc8bf7fd8ade246736dab064dec95b821d424b8bbc4a1c7b5a97286a5bfe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}